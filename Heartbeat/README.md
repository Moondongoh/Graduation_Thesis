1️⃣ 연구 프로젝트
--프로젝트 개요--

본 프로젝트는 심장음(heartbeat)과 같은 생체 오디오 신호에서 유용한 특징(feature)을 추출하고, 이를 머신러닝 및 딥러닝 모델 학습에 활용하기 위한 데이터 전처리 및 변환 방법을 구현하는 것을 목표로 한다.
추출된 특징은 신호의 통계적 특성 및 시간-주파수 정보를 반영하며, 전통적 머신러닝 모델과 딥러닝 모델 모두에 적용 가능하다.

-방법

1. 웨이블릿 기반 특징 추출 (wavelet.py)

-입력: WAV 형식 오디오 신호

-처리:
1차원 신호를 일정 길이(segment_length=512)로 분할
각 세그먼트에 대해 5단계 db4 웨이블릿 변환 수행
계수별 통계적 특징 추출: 평균(mean), 표준편차(std), 최댓값(max), 최솟값(min), 중앙값(median), 에너지(energy)

-출력: CSV 파일로 저장

-열(columns): A5_mean, A5_std, …, D1_energy, file

-행(row): 각 세그먼트별 특징값

2. MFCC + Mel-Spectrogram 기반 특징 추출 (mfs.py)

-입력: WAV 형식 오디오 신호

-처리:
MFCC(13차원) 및 Mel-Spectrogram(40차원) 추출
두 특징을 결합하여 2차원 배열(53 × T) 생성 (T: 시간 프레임 개수)

-출력: NumPy(.npy) 파일로 저장, CNN 입력에 바로 활용 가능

-결과

-웨이블릿 특징(CSV): 전통적 머신러닝 모델(랜덤포레스트, SVM, XGBoost 등) 학습에 적합

-MFS + MFCC 특징(NPY): CNN, ResNet, EfficientNet 등 딥러닝 모델 학습에 적합

-데이터셋 구조 비교:

CSV: 1차원 수치형

NPY: 2차원 이미지형

-결론

본 프로젝트는 동일한 오디오 데이터를 두 가지 방식으로 특징화함으로써, 신호 분석 및 모델 학습 실험에 유연성을 제공한다.
웨이블릿과 MFCC/Mel-Spectrogram 조합은 각각 신호의 통계적 특성과 시간-주파수 패턴을 효과적으로 반영한다.