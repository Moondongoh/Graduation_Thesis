# ============================================================
# 1. ìƒì„±ëœ í•™ìŠµ ëª¨ë¸ì„ ì´ìš©í•´ Validation ë°ì´í„° ì¶”ë¡ 

# - ì»¤ìŠ¤í…€ Dataset í´ë˜ìŠ¤ ì •ì˜
# â†’ validation í´ë”ì—ì„œ .png ì´ë¯¸ì§€ì™€ REFERENCE_binary.csvì˜ ë¼ë²¨ì„ ë§¤ì¹­

# - ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì •
# â†’ Resize(224x224) í›„ Tensor ë³€í™˜

# - CSV ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸°
# â†’ REFERENCE_binary.csvë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•´ Datasetì— ì „ë‹¬

# -ResNet18 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
# â†’ í´ë˜ìŠ¤ ìˆ˜ 2ê°œì— ë§ê²Œ FC ë ˆì´ì–´ ìˆ˜ì • í›„ í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜´

# - ê²€ì¦ ì´ë¯¸ì§€ ì¶”ë¡  ìˆ˜í–‰
# â†’ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ë° ì •í™•ë„ ì¶œë ¥

# - Confusion Matrix ì¶œë ¥
# â†’ ì‹œê°í™”í•˜ì—¬ ì„±ëŠ¥ í™•ì¸
# ============================================================
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
import os
import pandas as pd
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt


# 1. ì»¤ìŠ¤í…€ Dataset í´ë˜ìŠ¤ ì •ì˜
class HeartSoundValDataset(Dataset):
    def __init__(self, image_dir, label_dict, transform=None):
        self.image_dir = image_dir
        self.label_dict = label_dict
        self.image_files = [
            f
            for f in os.listdir(image_dir)
            if f.endswith(".png") and f.replace(".png", "") in label_dict
        ]
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx]
        img_path = os.path.join(self.image_dir, img_name)
        image = Image.open(img_path).convert("RGB")
        label = self.label_dict[img_name.replace(".png", "")]

        if self.transform:
            image = self.transform(image)

        return image, label, img_name


# 2. Transform ì •ì˜ (í•™ìŠµê³¼ ë™ì¼í•˜ê²Œ)
transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])

# 3. ë¼ë²¨ ë¡œë”©
label_df = pd.read_csv(
    r"E:/heartbeat/mels_images\validation/REFERENCE_binary.csv", header=None
)
label_df.columns = ["file_name", "label"]
label_dict = dict(zip(label_df["file_name"], label_df["label"]))

# 4. Dataset & DataLoader ìƒì„±
val_dataset = HeartSoundValDataset(
    image_dir="E:/heartbeat/mels_images/validation",
    label_dict=label_dict,
    transform=transform,
)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# 5. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = models.resnet18(pretrained=False)
model.fc = torch.nn.Linear(model.fc.in_features, 2)
model.load_state_dict(
    torch.load("../model/best_heart_cnn_model.pth", map_location=device)
)
model = model.to(device)
model.eval()

# 6. ì¶”ë¡  ë° ê²°ê³¼ ì €ì¥
correct = 0
total = 0
results = []
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels, img_names in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)

        correct += (preds == labels).sum().item()
        total += labels.size(0)

        # ì €ì¥ìš©
        for img_name, pred in zip(img_names, preds):
            results.append((img_name, pred.item()))

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# 7. ì •í™•ë„ ì¶œë ¥
accuracy = correct / total
print(f"âœ… Validation Accuracy: {accuracy:.4f}")

# 8. ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
df = pd.DataFrame(results, columns=["file_name", "predicted_label"])
df.to_csv("val_predictions.csv", index=False)
print("ğŸ“ ì˜ˆì¸¡ ê²°ê³¼ê°€ val_predictions.csvë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# 9. Confusion Matrix ì‹œê°í™”
cm = confusion_matrix(all_labels, all_preds)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()
